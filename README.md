# pipe query 

以下10条，是使用chatgpt 为 pq 工具写的“广告”:

1. 你是否曾经为在Linux命令行中进行文本处理而感到烦恼？现在，有了我的工具，使用SQL进行文本处理将变得轻而易举。

2. 你是否厌倦了手动处理大量文本数据的繁琐过程？使用我的工具，你可以像操作数据库一样处理文本数据，事半功倍。

3. 我的工具不仅可以在Linux命令行中使用，还可以让你享受到SQL的强大功能，处理文本数据从此不再是难事。

4. 你是否曾经为在Linux命令行中缺乏强大的文本处理工具而感到苦恼？我的工具将为你解决这个问题。

5. 无需将文本数据导入到数据库中，我的工具让你在Linux命令行中通过SQL对文本数据进行处理，提高了工作效率。

6. 如果你是一名Linux用户，我的工具将让你的文本处理工作更加高效、方便、快捷。

7. 你是否曾经因为在Linux命令行中没有强大的文本处理工具而感到受挫？我的工具将为你带来全新的文本处理体验。

8. 无需学习新的命令，使用我的工具，你可以将SQL的强大功能应用到Linux命令行中，让文本处理更加简单易用。

9. 我的工具充分利用了SQL的强大功能，让你在Linux命令行中快速处理大量文本数据，让你的工作事半功倍。

10. 无需花费大量时间和精力手动处理文本数据，我的工具让你使用SQL快速、简单地处理文本数据，让你的工作更加高效。

## 项目描述

用sql 来过滤、处理数据流

如： 日志分析、文件分析、文件过滤等等

可以作为 awk 的一种补充，或者你能想象的别的用处

## 本项目目的

1. 为学习sql,更深入了解sql以及其运行原理
2. 为文本处理多增一个工具


## 使用例子

直接写条件

```
ls -l | pq  -w "c5>1024" # c5 代表第五列
```

默认使用stdin 作为数据源，并且按列分割（空白字符），c1 c2 ... cn 

    默认支持50列，使用 -c 指定

也可以写完整的sql语句:

```
ls -l |pq -e "select * from stdin where c5>1024 limit 1,5"

```

- [x] 支持嵌套查询：

```
ls -l |./pq -e ' select * from (select * from stdin)'
```

更多例子，参考单元测试

## 数据源

- [x] stdin   标准输入 
    - [x] 按列分割
    - [ ] json
    - [ ] 自定义分隔符
- [ ] file   文件输入 
- [ ] kafka   kafka队列输入 
- [ ] mysql   从mysql输入 

